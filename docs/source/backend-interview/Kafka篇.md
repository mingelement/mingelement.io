# 这些年背过的面试题——Kafka篇

## Why Kafka?

Kafka 是一个分布式流处理平台，广泛用于大数据处理和实时分析。它具有高吞吐量、可伸缩性和持久化消息的特点，适用于日志收集、消息系统和用户活动跟踪等场景。

### 对比其他消息队列

- **RabbitMQ**：轻量级，支持AMQP协议，但性能和扩展性有限。
- **RocketMQ**：高性能，适合电商场景，但与周边系统的整合和兼容性不是很好。

## What Kafka

Kafka 的核心组件包括：

- **Producer API**：允许应用程序发布消息到一个或多个主题。
- **Consumer API**：允许应用程序订阅主题并处理消息流。
- **Streams API**：允许应用程序作为流处理器，转换输入流为输出流。

### 消息和主题

- **消息（Message）**：Kafka 的数据单元，类似于数据库中的一行记录。
- **批次（Batch）**：为了提高效率，消息被分批写入 Kafka。
- **主题（Topic）**：消息的分类，类似于数据库中的表。
- **分区（Partition）**：主题可以被分成多个分区，分布于 Kafka 集群中。

### 副本和节点

- **副本（Replicas）**：每个分区有多个副本，提高数据的可靠性。
- **生产者（Producer）**：将消息均衡地分布到主题的所有分区上。
- **消费者（Consumer）**：通过偏移量区分已读消息，消费消息。
- **消费组（Consumer Group）**：确保每个分区只能被一个消费者使用。
- **节点（Broker）**：连接生产者和消费者，处理消息的存储和检索。

## How Kafka

### 优点

- **高吞吐量**：单机每秒处理数百万消息。
- **高性能**：单节点支持上千客户端。
- **持久化**：消息持久化到磁盘。
- **分布式系统**：易扩展，所有组件均为分布式。

### 应用场景

- **日志收集**：收集各种服务的日志。
- **消息系统**：解耦生产者和消费者。
- **用户活动跟踪**：记录用户活动，如浏览、搜索、点击等。

### 生产消费基本流程

1. 生产者创建时，会创建一个 Sender 线程。
2. 生产的消息经过拦截器、序列化器、分区器，然后缓存在缓冲区。
3. 批次发送的条件为缓冲区数据大小或时间达到上限。
4. 批次发送后，消息发往指定分区，然后落盘到 broker。

### Leader选举和副本消息同步

- Kafka 会在 Zookeeper 上维护一个 ISR 集合，用于跟踪与 Leader 保持同步的副本。
- Leader 副本负责处理读写请求，Follower 副本定期从 Leader 拉取数据。

### Rebalance

当消费组内成员数量变化时，会触发 Rebalance 过程，重新分配分区给消费者。

### 增删改查

使用 Kafka 提供的命令行工具进行 Topic 的创建、删除、修改和查询。

### 一致性和可用性

- **幂等性**：确保消息不会重复处理。
- **数据不丢失**：通过配置 Producer 和 Broker 的参数确保数据的持久化。

## 面试题

### 线上问题 Rebalance

- 原因：组成员数量变化、订阅主题数量变化、分区数变化。
- 解决方案：调整超时时间和心跳频率。

### ZooKeeper 的作用

Kafka 使用 ZooKeeper 存放集群元数据、成员管理和 Controller 选举。

### Replica副本的作用

Kafka 只有 Leader 副本提供读写服务，Follower 副本同步 Leader 副本中的数据。

### 如何防止重复消费

- 提交 offset。
- 使用数据库唯一键约束或 Redis 检查 ID 是否被消费。

### 如何保证数据不会丢失

- 生产者配置 ack=all。
- Broker 配置 ISR 副本和重试机制。
- 消费者关闭自动提交 offset。

### 如何保证顺序消费

- 单 topic、单 partition、单 consumer、单线程消费。
- 为每个 key 申请单独内存 queue。

### 解决积压消费和避免消息积压

- 提高消费并行度。
- 批量消费。
- 减少组件 IO 交互次数。
- 优先级消费。

### 如何设计消息队列

考虑快速水平扩容、一致性、可用性、分区容错性和海量数据处理。